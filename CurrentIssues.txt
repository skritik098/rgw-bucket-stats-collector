### Issues or TO-DO List 

- The current script doesn't work with the COLD start scenario where the DB needs to be updated 
    and when the buckets count is already huge in the cluster.

- In the simialr aspect of above point, the multi-thread concept doesn't get scaled to 100 workers in the execution.
    - For 100 buckets, it took 5-6 sec, so if we have 15000 buckets and threshold value set to 10 mins will make 10k buckets get readded in the stale bucket along with remaining 5000
    - So the either scaling needs to be fixed to collect data in much more optimized way or scaled it way to collect the bucket stats for 1000s buckets in seconds.
    - Or update the default threshold to a certain value where large scale cluster can be managed. 

- There is no per bucket historical analytics available even though the code is available to do: 
    - historical global analytics and each bucket historical data stats historical anlytics **manually**
    - But there is no code base to show a comparision for each bucket in a tabular format.

- The current code also doesn't keep track of the sync activity for each bucket along with the bucket stats on the site where it is running.

- There is no Dashboard to view the overall track of such activity:
    - Updating the bucket stats as like how old the bucket stats is same as the oldest collected time
    - CLI based method would be great to have for this.


- The DB locking issue, where the collector keep the lock and dashboard would fails to do.

- Scalability is still not there.
----
No what I meant was not the feasiblity of scaling but not getting scaled actually.

On reviewing the number of radosgw-admin commands running in the system, i found that max number is not even crossing 50 

Since this code as of now works in batches of 100 buckets which get's done in 6 sec means 16-20 buckets get processed in a second. 
But i want this code to actually process 150-200 buckets per seconds mean there should be 200 radosgw-admin commands running instantly 
----



+++ Latest 7:15pm +++
the current bulk pull, pull all of the bucket stats but it did not update all of them rather
it update only the stale bucket entry.
    - this cause the issue is that for the next incremental those left out stale entries will also cause this complete pull again.
    - So sometime, we eventually ended up with multiple full bucket stats execution.

    